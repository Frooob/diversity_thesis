\chapter{Discussion}


Zu meinen Ergebnissen:
- PixelCorrelation ist nicht so gut (haben wir an vielen Ergebnissen schon irgendwie gesehen)


Generell:
- https://x.com/PTenigma/status/1893459033379807586
- Erklärung dafür, dass der brain-diffuser in clip so viel besser ist, ist vielleicht einfach die image-naturalness
- Man könnte auch noch den tatsächlichen test einfügen in die versatile diffusion
- Andere Image generation Algorithms (innerhalb des brain-diffuser Algorithm)
- Andere Decoder-Algorithmen (mindeye etc.)
    - Man könnte auch komplette captions generieren lassen und nicht nur die Features wie bei unibrain \cite{maiUniBrainUnifyImage2023}


- Um die rare concepts zu verbessern sagen \cite{samuelGeneratingImagesRare2024} dass man sich vor allem auf den diffusion input fokussieren muss


- Andere Reconstruction Algorithmen:
    - Theoretisch sind viele Contexts möglich bei dem versatile diffusion approach, mit einer weiterentwicklung könnte man so dann auch je nach image das regeneriert werden soll ganz unterschiedlichen kontext geben (das schreibe ich auch schon teilweise beim aicap Experiment)

